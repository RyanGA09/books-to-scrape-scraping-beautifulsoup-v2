{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Books to Scrape - Scraping: Advanced Version (V2)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as BfS4\n",
    "import wget\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book detail scraping function loaded.\n"
     ]
    }
   ],
   "source": [
    "# Function to retrieve data from the book's detail page\n",
    "def scrape_book_details(book_link):\n",
    "    try:\n",
    "        response = requests.get(book_link)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return {}\n",
    "\n",
    "    soup = BfS4(response.text, 'html.parser')\n",
    "    description = soup.find('meta', {'name': 'description'})\n",
    "    description = description['content'] if description else 'No description available'\n",
    "\n",
    "    price_incl_tax = price_excl_tax = price_tax = 'N/A'\n",
    "    for price_elem in ['Price (incl. tax)', 'Price (excl. tax)', 'Tax']:\n",
    "        price = soup.find('th', text=price_elem)\n",
    "        if price:\n",
    "            setattr(locals(), price_elem.lower().replace(\" \", \"_\"), price.find_next_sibling('td').text.strip())\n",
    "\n",
    "    return {\n",
    "        'description': description,\n",
    "        'price_incl_tax': price_incl_tax,\n",
    "        'price_excl_tax': price_excl_tax,\n",
    "        'price_tax': price_tax\n",
    "    }\n",
    "\n",
    "print(\"Book detail scraping function loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve book links from catalogs\n",
    "def scrape_links_of_books_from_page(page_url):\n",
    "    books_in_page = []\n",
    "    response = requests.get(page_url)\n",
    "    if response.ok:\n",
    "        soup = BfS4(response.content, \"html.parser\")\n",
    "        # Take all the articles with the \"product_pod\" class that contains the book's information\n",
    "        articles = soup.find_all(\"article\", class_=\"product_pod\")\n",
    "        for article in articles:\n",
    "            a = article.find(\"a\")\n",
    "            a_link = a[\"href\"]\n",
    "            # Create a full link to the book's detail page\n",
    "            books_in_page.append(f'http://books.toscrape.com/catalogue/{a_link.replace(\"../../../\", \"\")}')\n",
    "    return books_in_page\n",
    "\n",
    "print(\"Retrieve book links from catalogs function loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve the detailed data of a single book\n",
    "def scrape_book_data(book_link):\n",
    "    print(f\"Scraping {book_link} ...\")\n",
    "    response = requests.get(book_link)\n",
    "    if response.ok:\n",
    "        soup = BfS4(response.content, \"html.parser\")\n",
    "        image = soup.find(\"img\")\n",
    "        image_url = image[\"src\"].replace(\"../../\", \"http://books.toscrape.com/\")  # Changing relative urls to absolute\n",
    "        title = image[\"alt\"]\n",
    "        price = soup.find('p', class_='price_color').text\n",
    "        availability = soup.find(\"th\", text=\"Availability\").find_next_sibling(\"td\").string.strip()\n",
    "        rating = soup.find(\"p\", attrs={'class': 'star-rating'}).get(\"class\")[1]\n",
    "        details = scrape_book_details(book_link)\n",
    "        \n",
    "        data = {\n",
    "            \"Title\": title,\n",
    "            \"Price\": price,\n",
    "            \"Price including tax\": details['price_incl_tax'],\n",
    "            \"Price excluding tax\": details['price_excl_tax'],\n",
    "            \"Price Tax\": details['price_tax'],\n",
    "            \"Availability\": availability,\n",
    "            \"Product Description\": details['description'],\n",
    "            \"Rating\": rating,\n",
    "            \"Image URL\": image_url,\n",
    "            \"Link\": book_link\n",
    "        }\n",
    "        return data\n",
    "    return None\n",
    "\n",
    "print(\"Retrieve the detailed data of a single book function loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for scraping books from multiple catalog pages\n",
    "def scrape_books_from_pages(base_url, total_pages):\n",
    "    all_books = []\n",
    "    for page in range(1, total_pages + 1):\n",
    "        if page == 1:\n",
    "            url = base_url  # First Page\n",
    "        else:\n",
    "            url = f\"{base_url}catalogue/page-{page}.html\"  # Next Page\n",
    "\n",
    "        print(f\"Scraping page {page}: {url}\")\n",
    "        \n",
    "        # Grab all the book links from this page\n",
    "        books_in_page = scrape_links_of_books_from_page(url)\n",
    "        for book_link in books_in_page:\n",
    "            book_data = scrape_book_data(book_link)\n",
    "            if book_data:\n",
    "                all_books.append(book_data)\n",
    "\n",
    "        time.sleep(1)  # Provides a pause to avoid too many requests\n",
    "\n",
    "    return all_books\n",
    "\n",
    "print(\"Scraping books from multiple catalog pages function loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV saving function loaded.\n"
     ]
    }
   ],
   "source": [
    "# Function to save scraping results to a CSV file\n",
    "def save_to_csv(data, filename):\n",
    "    if not data:\n",
    "        print(\"No data to save.\")\n",
    "        return\n",
    "\n",
    "    keys = data[0].keys()\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=keys)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "print(\"CSV saving function loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'http://books.toscrape.com/'  # URL dasar untuk katalog buku\n",
    "total_pages = 3  # Jumlah halaman yang ingin di-scrape, bisa Anda ubah sesuai kebutuhan\n",
    "\n",
    "# Scrape buku dari beberapa halaman\n",
    "books_data = scrape_books_from_pages(base_url, total_pages)\n",
    "display(books_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_csv(books_data, 'books_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Main scraping process Success.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file and display the first few rows\n",
    "df = pd.read_csv('books_data.csv')\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
